# -*- coding: utf-8 -*-
"""News_Text_Multiclass_Classification_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yPfHKcqfTUGjDeN7Ydlpa-rys2OybNNo

# Perkenalan

Halo Kak Reviewer! Perkenalkan saya Rafka Imanda Putra dengan username dicoding rafka_imanda.

Dikesempatan kali ini saya akan mengirim submission pertama saya dalam Kelas Belajar Pengembangan Machine Learning.

Adapun dataset yang digunakan bersumber dari https://www.kaggle.com/kishanyadav/inshort-news dimana ini adalah dataset yang berisi mengenai 12.120 isi berita berdasar 7 label berbeda seperti technology,sports,politics,entertainment,world,automobile dan science.

Tujuan saya disini adalah membuat model yang mampu mengenali sebuah teks berita dan memprediksinya ke tujuh label target yang sesuai. Dan harapannya model yang saya buat bisa menyentuh akurasi 90% guna mendapatkan review 5 bintang dari reviewer.

Mungkin cukup sekian, mari kita mulai pemodelannya!

# Data Understanding

Context -
This data is collected by me on daily basis from inshorts news webapp.

Content -
This dataset have 3 columns named as news_headline, news_article, and news_category. It also contain news from 7 different categories like technology,sports,politics,entertainment,world,automobile and science.

Inspiration -
What types of machine learning models perform best on this dataset?
How multiclass classification works?

# Data Preparation
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

sns.set()
# %matplotlib inline

import io
from google.colab import files

import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Flatten, Dropout, Dense

files = files.upload()

news1 = pd.read_csv(io.BytesIO(files['inshort_news_data-1.csv']))
news2 = pd.read_csv(io.BytesIO(files['inshort_news_data-2.csv']))
news3 = pd.read_csv(io.BytesIO(files['inshort_news_data-3.csv']))
news4 = pd.read_csv(io.BytesIO(files['inshort_news_data-4.csv']))
news5 = pd.read_csv(io.BytesIO(files['inshort_news_data-5.csv']))
news6 = pd.read_csv(io.BytesIO(files['inshort_news_data-6.csv']))
news7 = pd.read_csv(io.BytesIO(files['inshort_news_data-7.csv']))

data = [news1, news2, news3, news4, news5, news6, news7]

df = pd.concat(data, axis=0, ignore_index=True)

df.head()

df.shape

df = df.drop(['Unnamed: 0', 'news_headline'], axis=1)

df.head()

plt.figure(figsize=(10,5))
sns.countplot(df['news_category'])
plt.xticks(rotation=45)
plt.show()

review = pd.get_dummies(df['news_category'])
df2 = pd.concat([df, review], axis=1)
df2 = df2.drop('news_category', axis=1)
df2.head()

"""# Splitting, Tokenizing, Padding"""

X = df2['news_article'].values
y = df2.drop('news_article', axis=1).values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

tokenizer = Tokenizer(num_words=10000, oov_token='n')

tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)

sequence_train = tokenizer.texts_to_sequences(X_train)
sequence_test = tokenizer.texts_to_sequences(X_test)

padded_train = pad_sequences(sequence_train)
padded_test = pad_sequences(sequence_test)

"""# Modelling"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy') > 0.92):
      print('\nYeay, akurasi memenuhi target!')
      self.model.stop_training = True

callbacks = myCallback()

model = Sequential([
                    Embedding(input_dim=10000, output_dim=128),
                    LSTM(128),
                    Flatten(),
                    Dropout(0.5),
                    Dense(128, activation='relu'),
                    Dense(64, activation='relu'),
                    Dense(7, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(padded_train, y_train, epochs=25, validation_data=(padded_test, y_test), callbacks=[callbacks], batch_size=256)

"""* wow, cukup dengan 11 epoch, model sudah mampu mengenali kategori berita dengan akurasi validasi sekitar 92,2%.

# Plot Loss & Akurasi Pelatihan Model
"""

plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='validation_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.ylim(ymin=0, ymax=1)
plt.show()

plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='validation_loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.ylim(ymin=0)
plt.show()

"""# Conclusion


Akurasi dari model di atas 80%. -- Done

Mengimplementasikan callback. -- Done

Membuat plot loss dan akurasi pada saat training dan validation. -- Done

Dataset memiliki 3 kelas atau lebih dan minimal 2000 sampel data. -- Done

Akurasi pada training set dan validation set di atas 90%. -- Done
"""